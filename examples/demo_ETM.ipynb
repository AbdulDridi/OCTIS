{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.pardir)\n",
    "from dataset.dataset import Dataset\n",
    "from evaluation_metrics.diversity_metrics import Topic_diversity\n",
    "from evaluation_metrics.topic_significance_metrics import KL_uniform\n",
    "from skopt import gp_minimize, forest_minimize, dummy_minimize\n",
    "from optimization.optimizer import Optimizer\n",
    "from skopt.space.space import Real, Integer\n",
    "import multiprocessing as mp\n",
    "from models import TorchETM\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "dataset.load(\"preprocessed_datasets/newsgroup/newsgroup_lemmatized_10\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = TorchETM.ETM_Wrapper()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model.hyperparameters['epochs'] = 20\n",
    "model.hyperparameters['enc_drop'] = 0.1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model.test_set(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.1, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=1268, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=10, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=1268, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=10, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=10, bias=True)\n",
      ")\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 515.16 .. NELBO: 515.22\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 507.0 .. NELBO: 507.02\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 0.2 .. Rec_loss: 506.07 .. NELBO: 506.27\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 0.47 .. Rec_loss: 504.88 .. NELBO: 505.35\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->5 .. LR: 0.005 .. KL_theta: 0.89 .. Rec_loss: 503.21 .. NELBO: 504.1\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->6 .. LR: 0.005 .. KL_theta: 1.07 .. Rec_loss: 502.68 .. NELBO: 503.75\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->7 .. LR: 0.005 .. KL_theta: 1.21 .. Rec_loss: 501.93 .. NELBO: 503.14\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->8 .. LR: 0.005 .. KL_theta: 1.39 .. Rec_loss: 501.32 .. NELBO: 502.71\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->9 .. LR: 0.005 .. KL_theta: 1.52 .. Rec_loss: 500.49 .. NELBO: 502.01\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->10 .. LR: 0.005 .. KL_theta: 1.62 .. Rec_loss: 499.91 .. NELBO: 501.53\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->11 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 499.8 .. NELBO: 501.48\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->12 .. LR: 0.005 .. KL_theta: 1.96 .. Rec_loss: 500.05 .. NELBO: 502.01\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->13 .. LR: 0.005 .. KL_theta: 1.87 .. Rec_loss: 499.79 .. NELBO: 501.66\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->14 .. LR: 0.005 .. KL_theta: 1.88 .. Rec_loss: 499.47 .. NELBO: 501.35\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->15 .. LR: 0.005 .. KL_theta: 1.99 .. Rec_loss: 498.33 .. NELBO: 500.32\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->16 .. LR: 0.005 .. KL_theta: 2.06 .. Rec_loss: 497.92 .. NELBO: 499.98\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->17 .. LR: 0.005 .. KL_theta: 2.11 .. Rec_loss: 498.79 .. NELBO: 500.9\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->18 .. LR: 0.005 .. KL_theta: 2.32 .. Rec_loss: 497.39 .. NELBO: 499.71\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->19 .. LR: 0.005 .. KL_theta: 2.39 .. Rec_loss: 497.46 .. NELBO: 499.85\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->20 .. LR: 0.005 .. KL_theta: 2.44 .. Rec_loss: 496.83 .. NELBO: 499.27\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'topics': [['be', 'moment', 'playoff', 'contain', 'represent'],\n  ['volume', 'great', 'convince', 'better', 'encryption'],\n  ['security', 'private', 'shipping', 'basically', 'role'],\n  ['victim', 'encryption', 'thread', 'turn', 'be'],\n  ['encryption', 'thread', 'be', 'turn', 'victim'],\n  ['mostly', 'screw', 'son', 'compute', 'attempt'],\n  ['victim', 'card', 'generation', 'method', 'past'],\n  ['victim', 'turn', 'playoff', 'thread', 'be'],\n  ['playoff', 'victim', 'be', 'license', 'school'],\n  ['victim', 'license', 'card', 'playoff', 'school']],\n 'topic-word-matrix': array([[3.5531379e-04, 9.3680067e-04, 1.5779298e-03, ..., 1.6453606e-03,\n         9.1919978e-04, 1.3440547e-03],\n        [4.6962657e-04, 8.3435618e-04, 4.8076722e-04, ..., 5.5757654e-04,\n         6.7299034e-04, 6.8086328e-04],\n        [4.7388798e-04, 1.2528567e-03, 1.8376140e-04, ..., 1.4141962e-04,\n         8.2850049e-04, 4.2553875e-04],\n        ...,\n        [1.3802102e-04, 1.3298292e-03, 1.3895563e-04, ..., 8.9416128e-05,\n         9.5900556e-04, 4.2097751e-04],\n        [1.4833822e-04, 1.2478021e-03, 4.9312424e-04, ..., 2.5602354e-04,\n         1.0644543e-03, 1.2707397e-03],\n        [1.0914552e-04, 1.2223460e-03, 4.2692339e-04, ..., 1.9839880e-04,\n         1.0513173e-03, 1.2355489e-03]], dtype=float32),\n 'topic-document-matrix': array([[0.0100736 , 0.00294269, 0.00282203, ..., 0.00429904, 0.00860372,\n         0.01105107],\n        [0.10228731, 0.04347385, 0.03564241, ..., 0.06103984, 0.11652871,\n         0.13698228],\n        [0.10866731, 0.04916317, 0.04043988, ..., 0.06967168, 0.1177547 ,\n         0.12927674],\n        ...,\n        [0.12008313, 0.09732161, 0.08103395, ..., 0.10610957, 0.10791955,\n         0.10487982],\n        [0.10069226, 0.04266516, 0.03503904, ..., 0.05976245, 0.12461112,\n         0.147808  ],\n        [0.12270293, 0.07546744, 0.06311779, ..., 0.09060991, 0.12726615,\n         0.13592893]], dtype=float32)}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(dataset, model.hyperparameters, top_words= 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "{'topics': [['be', 'moment', 'playoff', 'contain', 'represent'],\n  ['volume', 'great', 'convince', 'better', 'encryption'],\n  ['security', 'private', 'shipping', 'basically', 'role'],\n  ['victim', 'encryption', 'thread', 'turn', 'be'],\n  ['encryption', 'thread', 'be', 'turn', 'victim'],\n  ['mostly', 'screw', 'son', 'compute', 'attempt'],\n  ['victim', 'card', 'generation', 'method', 'past'],\n  ['victim', 'turn', 'playoff', 'thread', 'be'],\n  ['playoff', 'victim', 'be', 'license', 'school'],\n  ['victim', 'license', 'card', 'playoff', 'school']],\n 'topic-word-matrix': array([[3.5531379e-04, 9.3680067e-04, 1.5779298e-03, ..., 1.6453606e-03,\n         9.1919978e-04, 1.3440547e-03],\n        [4.6962657e-04, 8.3435618e-04, 4.8076722e-04, ..., 5.5757654e-04,\n         6.7299034e-04, 6.8086328e-04],\n        [4.7388798e-04, 1.2528567e-03, 1.8376140e-04, ..., 1.4141962e-04,\n         8.2850049e-04, 4.2553875e-04],\n        ...,\n        [1.3802102e-04, 1.3298292e-03, 1.3895563e-04, ..., 8.9416128e-05,\n         9.5900556e-04, 4.2097751e-04],\n        [1.4833822e-04, 1.2478021e-03, 4.9312424e-04, ..., 2.5602354e-04,\n         1.0644543e-03, 1.2707397e-03],\n        [1.0914552e-04, 1.2223460e-03, 4.2692339e-04, ..., 1.9839880e-04,\n         1.0513173e-03, 1.2355489e-03]], dtype=float32),\n 'topic-document-matrix': array([[0.0100736 , 0.00294269, 0.00282203, ..., 0.00429904, 0.00860372,\n         0.01105107],\n        [0.10228731, 0.04347385, 0.03564241, ..., 0.06103984, 0.11652871,\n         0.13698228],\n        [0.10866731, 0.04916317, 0.04043988, ..., 0.06967168, 0.1177547 ,\n         0.12927674],\n        ...,\n        [0.12008313, 0.09732161, 0.08103395, ..., 0.10610957, 0.10791955,\n         0.10487982],\n        [0.10069226, 0.04266516, 0.03503904, ..., 0.05976245, 0.12461112,\n         0.147808  ],\n        [0.12270293, 0.07546744, 0.06311779, ..., 0.09060991, 0.12726615,\n         0.13592893]], dtype=float32),\n 'test-topic-document-matrix': array([[0.11228547, 0.09800858, 0.08301944, ..., 0.09449203, 0.11012072,\n         0.11502197],\n        [0.03908895, 0.023146  , 0.02108472, ..., 0.02405164, 0.03190448,\n         0.03382384],\n        [0.01877639, 0.00772652, 0.00735479, ..., 0.00952264, 0.01504528,\n         0.01794644],\n        ...,\n        [0.0932194 , 0.0961488 , 0.08605241, ..., 0.07856037, 0.08118891,\n         0.08638552],\n        [0.10278697, 0.08736052, 0.08211467, ..., 0.08777294, 0.08925916,\n         0.09736957],\n        [0.11052237, 0.12118949, 0.09778921, ..., 0.10846887, 0.09203418,\n         0.09147629]])}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inference()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}