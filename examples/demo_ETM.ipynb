{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.pardir)\n",
    "from dataset.dataset import Dataset\n",
    "from evaluation_metrics.diversity_metrics import Topic_diversity\n",
    "from evaluation_metrics.topic_significance_metrics import KL_uniform\n",
    "from skopt import gp_minimize, forest_minimize, dummy_minimize\n",
    "from optimization.optimizer import Optimizer\n",
    "from skopt.space.space import Real, Integer\n",
    "import multiprocessing as mp\n",
    "from models import TorchETM\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "dataset.load(\"preprocessed_datasets/newsgroup/newsgroup_lemmatized_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = TorchETM.ETM_Wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.hyperparameters['num_epochs'] = 3\n",
    "model.hyperparameters['enc_drop'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.partitioning(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True pre_set_model\n",
      "True pre_set_default_hyp\n",
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.1, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=1268, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=10, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=1268, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=10, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=10, bias=True)\n",
      ")\n",
      "True post_set_model\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 515.16 .. NELBO: 515.22\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 507.0 .. NELBO: 507.02\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 0.2 .. Rec_loss: 506.07 .. NELBO: 506.27\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'topics': [['victim',\n   'playoff',\n   'card',\n   'library',\n   'turn',\n   'past',\n   'license',\n   'be',\n   'school',\n   'generation'],\n  ['victim',\n   'playoff',\n   'license',\n   'be',\n   'past',\n   'school',\n   'library',\n   'method',\n   'turn',\n   'card'],\n  ['victim',\n   'playoff',\n   'license',\n   'be',\n   'past',\n   'library',\n   'card',\n   'school',\n   'method',\n   'generation'],\n  ['victim',\n   'playoff',\n   'be',\n   'license',\n   'past',\n   'library',\n   'card',\n   'school',\n   'turn',\n   'method'],\n  ['victim',\n   'playoff',\n   'turn',\n   'past',\n   'library',\n   'card',\n   'license',\n   'be',\n   'school',\n   'generation'],\n  ['victim',\n   'license',\n   'be',\n   'playoff',\n   'past',\n   'school',\n   'method',\n   'soldier',\n   'volume',\n   'encryption'],\n  ['victim',\n   'playoff',\n   'past',\n   'license',\n   'be',\n   'library',\n   'card',\n   'school',\n   'turn',\n   'method'],\n  ['victim',\n   'playoff',\n   'turn',\n   'library',\n   'card',\n   'past',\n   'be',\n   'license',\n   'generation',\n   'thread'],\n  ['victim',\n   'playoff',\n   'turn',\n   'library',\n   'license',\n   'card',\n   'past',\n   'be',\n   'school',\n   'thread'],\n  ['victim',\n   'playoff',\n   'license',\n   'be',\n   'library',\n   'past',\n   'school',\n   'card',\n   'turn',\n   'method']],\n 'test-topic-document-matrix': array([[0.09420644, 0.10068217, 0.11402649, ..., 0.09594224, 0.08408224,\n         0.09089164],\n        [0.08122973, 0.1048632 , 0.12769859, ..., 0.08278248, 0.07209755,\n         0.08512861],\n        [0.09111452, 0.10085369, 0.1193118 , ..., 0.09341636, 0.07915258,\n         0.08739438],\n        ...,\n        [0.07261651, 0.10896921, 0.13357937, ..., 0.0736365 , 0.06703819,\n         0.08440693],\n        [0.09926232, 0.1000141 , 0.10369668, ..., 0.10075109, 0.09505329,\n         0.09804253],\n        [0.11510081, 0.0938151 , 0.09094972, ..., 0.11601897, 0.10727224,\n         0.09965848]])}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(dataset, model.hyperparameters, top_words= 10,\n",
    "                  topic_word_matrix=False,\n",
    "                    topic_document_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Topic diversity\n",
    "topic_diversity = Topic_diversity()\n",
    "\n",
    "# KL_Uniform\n",
    "#kl_uniform = KL_uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Define optimization parameters\n",
    "opt_params = {}\n",
    "opt_params[\"n_calls\"] = 30\n",
    "opt_params[\"minimizer\"] = forest_minimize\n",
    "opt_params[\"different_iteration\"] = 3\n",
    "opt_params[\"n_random_starts\"] = 5\n",
    "#opt_params[\"extra_metrics\"] = [kl_uniform] # List of extra metrics\n",
    "opt_params[\"n_jobs\"] = mp.cpu_count() -1 # Enable multiprocessing\n",
    "opt_params[\"verbose\"] = True\n",
    "opt_params[\"save_path\"] = \"results\" #create folder if it doesn't exist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Create search space for optimization\n",
    "search_space = {\n",
    "    \"num_epochs\": Integer(low=5, high=10),\n",
    "    #\"eta\": Real(low=0.01, high=5.0)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = Optimizer(\n",
    "    model,\n",
    "    dataset,\n",
    "    topic_diversity,\n",
    "    search_space,\n",
    "    opt_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Disable computing of topic document matrix to optimize performance\n",
    "optimizer.topic_document_matrix = False\n",
    "optimizer.topic_word_matrix = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "------------------------------------------\n",
      "Bayesian optimization parameters:\n",
      "-n_calls:  30 \n",
      "-optimization_runs:  3 \n",
      "-model_runs:  10 \n",
      "-n_random_starts:  5 \n",
      "-minimizer:  forest_minimize\n",
      "-acq_func:  LCB\n",
      "------------------------------------------\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "True pre_set_model\n",
      "True pre_set_default_hyp\n",
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.1, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=1268, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=10, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=1268, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=10, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=10, bias=True)\n",
      ")\n",
      "True post_set_model\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 515.16 .. NELBO: 515.22\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 507.0 .. NELBO: 507.02\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 0.2 .. Rec_loss: 506.07 .. NELBO: 506.27\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 0.47 .. Rec_loss: 504.88 .. NELBO: 505.35\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->5 .. LR: 0.005 .. KL_theta: 0.89 .. Rec_loss: 503.21 .. NELBO: 504.1\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->6 .. LR: 0.005 .. KL_theta: 1.07 .. Rec_loss: 502.68 .. NELBO: 503.75\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->7 .. LR: 0.005 .. KL_theta: 1.21 .. Rec_loss: 501.93 .. NELBO: 503.14\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->8 .. LR: 0.005 .. KL_theta: 1.39 .. Rec_loss: 501.32 .. NELBO: 502.71\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->9 .. LR: 0.005 .. KL_theta: 1.52 .. Rec_loss: 500.49 .. NELBO: 502.01\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->10 .. LR: 0.005 .. KL_theta: 1.62 .. Rec_loss: 499.91 .. NELBO: 501.53\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Words in topics are less than 10",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mException\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-23-3756cd9a50fa>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Optimize\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mres\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhyperparameters\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# Best values for the hyperparameters\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mres\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction_values\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# Score of the optimized metric\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Data_Science_all\\MSC_2_anno\\topic-modeling-evaluation-framework\\optimization\\optimizer.py\u001B[0m in \u001B[0;36moptimize\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    555\u001B[0m                             \u001B[0mxi\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0mdefault_parameters\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"xi\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    556\u001B[0m                             \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdefault_parameters\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"n_jobs\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 557\u001B[1;33m                             \u001B[0mmodel_queue_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdefault_parameters\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"model_queue_size\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    558\u001B[0m         )    \n\u001B[0;32m    559\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Data_Science_all\\MSC_2_anno\\topic-modeling-evaluation-framework\\optimization\\optimizer.py\u001B[0m in \u001B[0;36mBayesian_optimization\u001B[1;34m(self, f, bounds, minimizer, number_of_call, optimization_runs, model_runs, kernel, acq_func, base_estimator_forest, random_state, noise_level, alpha, kappa, X0, Y0, time_x0, n_random_starts, save, save_step, save_name, save_path, early_stop, early_step, plot_optimization, plot_model, plot_name, log_scale_plot, verbose, n_points, xi, n_jobs, model_queue_size)\u001B[0m\n\u001B[0;32m    463\u001B[0m                                     \u001B[0mmetric_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetric\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    464\u001B[0m                                     \u001B[0mnum_topic\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhyperparameters\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'num_topics'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 465\u001B[1;33m                                     maximize=(self.optimization_type == 'Maximize') )\n\u001B[0m\u001B[0;32m    466\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    467\u001B[0m         \u001B[1;31m#GP Minimize\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Data_Science_all\\MSC_2_anno\\topic-modeling-evaluation-framework\\optimization\\forest_minimizer.py\u001B[0m in \u001B[0;36mforest_minimizer\u001B[1;34m(f, bounds, number_of_call, optimization_runs, model_runs, acq_func, base_estimator_forest, random_state, kappa, x0, y0, time_x0, n_random_starts, save, save_step, save_name, save_path, early_stop, early_step, plot_optimization, plot_model, plot_name, log_scale_plot, verbose, n_points, xi, n_jobs, model_queue_size, checkpoint_saver, dataset_name, hyperparameters_name, metric_name, num_topic, maximize)\u001B[0m\n\u001B[0;32m     72\u001B[0m                                         \u001B[0mkappa\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkappa\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     73\u001B[0m                                         \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 74\u001B[1;33m                                         model_queue_size=model_queue_size ) )\n\u001B[0m\u001B[0;32m     75\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mplot_optimization\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m             \u001B[0mtool\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot_bayesian_optimization\u001B[0m\u001B[1;33m(\u001B[0m \u001B[0mres\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlog_scale_plot\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpath\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msave_path\u001B[0m \u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\torch_env\\lib\\site-packages\\skopt\\optimizer\\forest.py\u001B[0m in \u001B[0;36mforest_minimize\u001B[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs, model_queue_size)\u001B[0m\n\u001B[0;32m    174\u001B[0m                          \u001B[0mxi\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mxi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkappa\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkappa\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    175\u001B[0m                          \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcallback\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0macq_optimizer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"sampling\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 176\u001B[1;33m                          model_queue_size=model_queue_size)\n\u001B[0m",
      "\u001B[1;32m~\\Anaconda3\\envs\\torch_env\\lib\\site-packages\\skopt\\optimizer\\base.py\u001B[0m in \u001B[0;36mbase_minimize\u001B[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001B[0m\n\u001B[0;32m    270\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mn\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_calls\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    271\u001B[0m         \u001B[0mnext_x\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mask\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 272\u001B[1;33m         \u001B[0mnext_y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnext_x\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    273\u001B[0m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtell\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnext_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnext_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    274\u001B[0m         \u001B[0mresult\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspecs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspecs\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Data_Science_all\\MSC_2_anno\\topic-modeling-evaluation-framework\\optimization\\optimizer.py\u001B[0m in \u001B[0;36m_objective_function\u001B[1;34m(self, hyperparameters, path)\u001B[0m\n\u001B[0;32m    174\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    175\u001B[0m         \u001B[1;31m# Get metric score\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 176\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetric\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscore\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_output\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    177\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    178\u001B[0m         \u001B[1;31m# Update metrics values for extra metrics\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Data_Science_all\\MSC_2_anno\\topic-modeling-evaluation-framework\\evaluation_metrics\\diversity_metrics.py\u001B[0m in \u001B[0;36mscore\u001B[1;34m(self, model_output)\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtopics\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_output\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"topics\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtopk\u001B[0m \u001B[1;33m>=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtopics\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 45\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Words in topics are less than '\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtopk\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     46\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m             \u001B[0munique_words\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mException\u001B[0m: Words in topics are less than 10"
     ]
    }
   ],
   "source": [
    "# Optimize\n",
    "res = optimizer.optimize()\n",
    "\n",
    "print(res.hyperparameters) # Best values for the hyperparameters\n",
    "print(res.function_values) # Score of the optimized metric\n",
    "print(\"Optimized metric: \"+res.optimized_metric)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}