{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.pardir)\n",
    "from dataset.dataset import Dataset\n",
    "from evaluation_metrics.diversity_metrics import Topic_diversity\n",
    "from evaluation_metrics.topic_significance_metrics import KL_uniform\n",
    "from skopt import gp_minimize, forest_minimize, dummy_minimize\n",
    "from optimization.optimizer import Optimizer\n",
    "from skopt.space.space import Real, Integer\n",
    "import multiprocessing as mp\n",
    "from models import TorchETM\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "dataset.load(\"preprocessed_datasets/newsgroup/newsgroup_lemmatized_10\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = TorchETM.ETM_Wrapper()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model.hyperparameters['epochs'] = 5\n",
    "model.hyperparameters['enc_drop'] = 0.1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model.test_set(False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.1, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=1268, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=10, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=1268, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=10, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=10, bias=True)\n",
      ")\n",
      "****************************************************************************************************\n",
      "Epoch----->0 .. LR: 0.005 .. KL_theta: 0.04 .. Rec_loss: 502.39 .. NELBO: 502.43\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 0.65 .. Rec_loss: 497.05 .. NELBO: 497.7\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 1.42 .. Rec_loss: 493.05 .. NELBO: 494.47\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 2.57 .. Rec_loss: 488.28 .. NELBO: 490.85\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 2.93 .. Rec_loss: 486.63 .. NELBO: 489.56\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'topics': [['turn', 'victim', 'playoff', 'thread', 'library'],\n  ['turn', 'playoff', 'victim', 'thread', 'guess'],\n  ['son', 'shipping', 'screw', 'security', 'mostly'],\n  ['victim', 'playoff', 'method', 'library', 'past'],\n  ['turn', 'playoff', 'victim', 'thread', 'library'],\n  ['victim', 'playoff', 'turn', 'library', 'thread'],\n  ['victim', 'playoff', 'turn', 'library', 'thread'],\n  ['generation', 'card', 'license', 'hope', 'victim'],\n  ['encryption', 'school', 'manner', 'base', 'basis'],\n  ['military', 'method', 'generation', 'food', 'bunch']],\n 'topic-word-matrix': array([[8.4459745e-05, 1.8019975e-03, 1.9959357e-04, ..., 1.4792911e-04,\n         1.0343851e-03, 7.7922530e-05],\n        [9.0886628e-05, 1.9206755e-03, 2.3516656e-04, ..., 1.8121021e-04,\n         1.1289663e-03, 9.2179056e-05],\n        [3.1988561e-04, 1.1765852e-03, 4.9168520e-05, ..., 2.6914446e-05,\n         3.0845561e-04, 5.1107359e-05],\n        ...,\n        [1.7030124e-04, 7.2725926e-04, 4.6173940e-04, ..., 4.7927702e-04,\n         9.6326054e-04, 7.4214541e-04],\n        [8.8123238e-04, 1.2604146e-03, 3.7272790e-04, ..., 4.9419771e-04,\n         1.1269918e-03, 1.8060704e-03],\n        [5.0127576e-04, 8.4344402e-04, 1.9110633e-04, ..., 1.3101257e-04,\n         6.3231675e-04, 5.6500488e-04]], dtype=float32),\n 'topic-document-matrix': array([[0.12161378, 0.1137028 , 0.09090816, ..., 0.0770178 , 0.09267509,\n         0.08164382],\n        [0.03293894, 0.03547102, 0.02279639, ..., 0.5970564 , 0.03751391,\n         0.1054326 ],\n        [0.1239126 , 0.12501803, 0.04688322, ..., 0.06939889, 0.16560286,\n         0.0401555 ],\n        ...,\n        [0.05379953, 0.05434384, 0.09976836, ..., 0.08238517, 0.04045469,\n         0.39753506],\n        [0.08830409, 0.08466124, 0.44804084, ..., 0.03661877, 0.03573737,\n         0.03420241],\n        [0.08111894, 0.08298507, 0.04276054, ..., 0.12696084, 0.29095224,\n         0.04310686]], dtype=float32)}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(dataset, model.hyperparameters, top_words= 5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}