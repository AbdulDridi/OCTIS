{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.pardir)\n",
    "from dataset.dataset import Dataset\n",
    "from evaluation_metrics.diversity_metrics import Topic_diversity\n",
    "from evaluation_metrics.topic_significance_metrics import KL_uniform\n",
    "from skopt import gp_minimize, forest_minimize, dummy_minimize\n",
    "from optimization.optimizer import Optimizer\n",
    "from skopt.space.space import Real, Integer\n",
    "import multiprocessing as mp\n",
    "from models.TorchAvitm import TorchAvitm\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = Dataset()\n",
    "dataset.load(\"preprocessed_datasets/newsgroup/newsgroup_lemmatized_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = TorchAvitm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set model hyperparameters\n",
    "model.hyperparameters['prior_variance'] = 0.2\n",
    "model.hyperparameters['n_components'] = 5\n",
    "model.hyperparameters['num_epochs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'prior_variance': 0.2, 'n_components': 5, 'num_epochs': 1}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "#Set true for splitting the dataset into train and test\n",
    "model.test_set(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: \n",
      "               N Components: 5\n",
      "               Topic Prior Mean: 0.0\n",
      "               Topic Prior Variance: 0.2\n",
      "               Model Type: prodLDA\n",
      "               Hidden Sizes: (100, 100)\n",
      "               Activation: softplus\n",
      "               Dropout: 0.2\n",
      "               Learn Priors: True\n",
      "               Learning Rate: 0.002\n",
      "               Momentum: 0.99\n",
      "               Reduce On Plateau: False\n",
      "               Save Dir: None\n",
      "Epoch: [1/1]\tSamples: [10758/10758]\tTrain Loss: 572.939630205247\tTime: 0:00:01.410117\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'topics': [['think',\n   'point',\n   'take',\n   'time',\n   'much',\n   'keep',\n   'could',\n   'want',\n   'would',\n   'first'],\n  ['make',\n   'different',\n   'first',\n   'can',\n   'follow',\n   'time',\n   'life',\n   'want',\n   'show',\n   'go'],\n  ['reaction',\n   'bug',\n   'additional',\n   'sick',\n   'worry',\n   'upgrade',\n   'electronic',\n   'assumption',\n   'notice',\n   'relation'],\n  ['popular',\n   'relatively',\n   'external',\n   'definitely',\n   'component',\n   'damn',\n   'hate',\n   'wave',\n   'aware',\n   'nee'],\n  ['take',\n   'point',\n   'time',\n   'could',\n   'play',\n   'go',\n   'good',\n   'may',\n   'look',\n   'need']],\n 'topic-word-matrix': array([[-0.06387644, -0.02884979, -0.12014884, ..., -0.06780745,\n         -0.02669834,  0.00446412],\n        [ 0.0072318 ,  0.03961246,  0.01168362, ...,  0.02178026,\n          0.00681433,  0.00666754],\n        [ 0.12584908, -0.12996095,  0.0762203 , ...,  0.13398783,\n         -0.06785965,  0.02153581],\n        [-0.03130642,  0.07545217,  0.082389  , ..., -0.12972291,\n          0.12962998,  0.09178702],\n        [ 0.01834664, -0.05632924,  0.01169136, ..., -0.00256405,\n          0.04307524,  0.04724117]], dtype=float32),\n 'topic-document-matrix': array([[0.01546959, 0.35773015, 0.5027484 , 0.08465993, 0.03939192],\n        [0.44430217, 0.00611429, 0.14407691, 0.39908198, 0.00642468],\n        [0.21940765, 0.542969  , 0.0741813 , 0.07812145, 0.0853207 ],\n        ...,\n        [0.00636725, 0.01621156, 0.89877087, 0.07414468, 0.00450562],\n        [0.03547002, 0.00261813, 0.03828856, 0.50859255, 0.4150307 ],\n        [0.46236497, 0.08082641, 0.04443769, 0.02456905, 0.3878019 ]],\n       dtype=float32)}"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.train_model(dataset, model.hyperparameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "{'topics': [['think',\n   'point',\n   'take',\n   'time',\n   'much',\n   'keep',\n   'could',\n   'want',\n   'would',\n   'first'],\n  ['make',\n   'different',\n   'first',\n   'can',\n   'follow',\n   'time',\n   'life',\n   'want',\n   'show',\n   'go'],\n  ['reaction',\n   'bug',\n   'additional',\n   'sick',\n   'worry',\n   'upgrade',\n   'electronic',\n   'assumption',\n   'notice',\n   'relation'],\n  ['popular',\n   'relatively',\n   'external',\n   'definitely',\n   'component',\n   'damn',\n   'hate',\n   'wave',\n   'aware',\n   'nee'],\n  ['take',\n   'point',\n   'time',\n   'could',\n   'play',\n   'go',\n   'good',\n   'may',\n   'look',\n   'need']],\n 'topic-word-matrix': array([[-0.06387644, -0.02884979, -0.12014884, ..., -0.06780745,\n         -0.02669834,  0.00446412],\n        [ 0.0072318 ,  0.03961246,  0.01168362, ...,  0.02178026,\n          0.00681433,  0.00666754],\n        [ 0.12584908, -0.12996095,  0.0762203 , ...,  0.13398783,\n         -0.06785965,  0.02153581],\n        [-0.03130642,  0.07545217,  0.082389  , ..., -0.12972291,\n          0.12962998,  0.09178702],\n        [ 0.01834664, -0.05632924,  0.01169136, ..., -0.00256405,\n          0.04307524,  0.04724117]], dtype=float32),\n 'topic-document-matrix': array([[0.01546959, 0.35773015, 0.5027484 , 0.08465993, 0.03939192],\n        [0.44430217, 0.00611429, 0.14407691, 0.39908198, 0.00642468],\n        [0.21940765, 0.542969  , 0.0741813 , 0.07812145, 0.0853207 ],\n        ...,\n        [0.00636725, 0.01621156, 0.89877087, 0.07414468, 0.00450562],\n        [0.03547002, 0.00261813, 0.03828856, 0.50859255, 0.4150307 ],\n        [0.46236497, 0.08082641, 0.04443769, 0.02456905, 0.3878019 ]],\n       dtype=float32),\n 'test-topic-document-matrix': array([[0.1262577 , 0.36539084, 0.10529645, 0.06739809, 0.33565685],\n        [0.5934218 , 0.17291681, 0.01047168, 0.18951829, 0.03367132],\n        [0.07004686, 0.19100507, 0.00954196, 0.0065664 , 0.7228398 ],\n        ...,\n        [0.03008257, 0.0801279 , 0.2357701 , 0.28913155, 0.36488786],\n        [0.16272402, 0.19269821, 0.02287922, 0.30181244, 0.3198861 ],\n        [0.00633774, 0.01345065, 0.03724055, 0.8091942 , 0.13377684]],\n       dtype=float32)}"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the predict method for the test set\n",
    "model.inference()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "'''\n",
    "Check vocabolary keys differences\n",
    "diz_tr = model.X_train.__dict__['idx2token']\n",
    "inv_map = {v: k for k, v in diz_tr.items()}\n",
    "diz_da = dataset.get_vocabulary()\n",
    "set(inv_map.keys()) == set(diz_da.keys())\n",
    "len(diz_da.keys())\n",
    "len(inv_map.keys())\n",
    "list1 = list(inv_map.keys())\n",
    "list2 = list(diz_da.keys())\n",
    "set_difference = set(list2) - set(list1)\n",
    "list_difference = list(set_difference)\n",
    "list_difference\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Topic diversity\n",
    "topic_diversity = Topic_diversity()\n",
    "\n",
    "# KL_Uniform\n",
    "#kl_uniform = KL_uniform()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimization parameters\n",
    "opt_params = {}\n",
    "opt_params[\"n_calls\"] = 30\n",
    "opt_params[\"minimizer\"] = forest_minimize\n",
    "opt_params[\"different_iteration\"] = 3\n",
    "opt_params[\"n_random_starts\"] = 5\n",
    "#opt_params[\"extra_metrics\"] = [kl_uniform] # List of extra metrics\n",
    "opt_params[\"n_jobs\"] = mp.cpu_count() -1 # Enable multiprocessing\n",
    "opt_params[\"verbose\"] = True\n",
    "opt_params[\"save_path\"] = \"results\" #create folder if it doesn't exist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create search space for optimization\n",
    "search_space = {\n",
    "    \"num_epochs\": Integer(low=1, high=50),\n",
    "    #\"eta\": Real(low=0.01, high=5.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = Optimizer(\n",
    "    model,\n",
    "    dataset,\n",
    "    topic_diversity,\n",
    "    search_space,\n",
    "    opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable computing of topic document matrix to optimize performance\n",
    "optimizer.topic_document_matrix = False\n",
    "optimizer.topic_word_matrix = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize\n",
    "res = optimizer.optimize()\n",
    "\n",
    "print(res.hyperparameters) # Best values for the hyperparameters\n",
    "print(res.function_values) # Score of the optimized metric\n",
    "print(\"Optimized metric: \"+res.optimized_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}