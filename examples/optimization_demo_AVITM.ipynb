{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.pardir)\n",
    "from dataset.dataset import Dataset\n",
    "from evaluation_metrics.diversity_metrics import Topic_diversity\n",
    "from evaluation_metrics.topic_significance_metrics import KL_uniform\n",
    "from skopt import gp_minimize, forest_minimize, dummy_minimize\n",
    "from optimization.optimizer import Optimizer\n",
    "from skopt.space.space import Real, Integer\n",
    "import multiprocessing as mp\n",
    "from models.TorchAvitm import TorchAvitm\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = Dataset()\n",
    "dataset.load(\"preprocessed_datasets/newsgroup/newsgroup_lemmatized_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = TorchAvitm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model hyperparameters\n",
    "model.hyperparameters['prior_variance'] = 0.2\n",
    "model.hyperparameters['n_components'] = 5\n",
    "model.hyperparameters['num_epochs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'prior_variance': 0.2, 'n_components': 5, 'num_epochs': 1}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model.test_set(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: \n",
      "               N Components: 5\n",
      "               Topic Prior Mean: 0.0\n",
      "               Topic Prior Variance: 0.2\n",
      "               Model Type: prodLDA\n",
      "               Hidden Sizes: (100, 100)\n",
      "               Activation: softplus\n",
      "               Dropout: 0.2\n",
      "               Learn Priors: True\n",
      "               Learning Rate: 0.002\n",
      "               Momentum: 0.99\n",
      "               Reduce On Plateau: False\n",
      "               Save Dir: None\n",
      "Epoch: [1/1]\tSamples: [10840/10840]\tTrain Loss: 16921.15939806273\tTime: 0:00:01.658081\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'topics': [['numerous',\n   'strong',\n   'usual',\n   'cd',\n   'motorcycle',\n   'class',\n   'junk',\n   'hate',\n   'russian',\n   'offense'],\n  ['identical',\n   'schedule',\n   'sure',\n   'numerous',\n   'routine',\n   'class',\n   'offense',\n   'cd',\n   'pack',\n   'solution'],\n  ['able',\n   'absolute',\n   'absolutely',\n   'block',\n   'gold',\n   'permission',\n   'technical',\n   'claim',\n   'instead',\n   'virtual'],\n  ['ability',\n   'raid',\n   'solar',\n   'instead',\n   'fully',\n   'approach',\n   'pin',\n   'claim',\n   'broad',\n   'permission'],\n  ['critical',\n   'approach',\n   'though',\n   'newspaper',\n   'money',\n   'understand',\n   'cheap',\n   'question',\n   'made',\n   'chapter']],\n 'topic-word-matrix': array([[ 0.06448709, -0.07448873, -0.05896251, ...,  0.09091718,\n          0.13554999, -0.04824581],\n        [ 0.04284371, -0.1182145 , -0.2066232 , ..., -0.02207693,\n         -0.08595788, -0.02793388],\n        [-0.12040485,  0.20028178,  0.14171745, ..., -0.14064965,\n         -0.1648739 , -0.2327408 ],\n        [ 0.04093582, -0.12521055, -0.17155811, ..., -0.1152501 ,\n         -0.08208551, -0.11283354],\n        [ 0.05944915, -0.00771878, -0.01724347, ...,  0.11489209,\n          0.129353  ,  0.14590819]], dtype=float32),\n 'topic-document-matrix': array([[3.28091949e-01, 7.39573361e-03, 2.04673856e-01, 1.26729399e-01,\n         3.33109081e-01],\n        [5.09221293e-03, 8.86786205e-04, 3.65684777e-02, 9.40894067e-01,\n         1.65585037e-02],\n        [2.09780484e-01, 8.56023058e-02, 4.15043570e-02, 4.19030748e-02,\n         6.21209741e-01],\n        ...,\n        [3.70931298e-01, 3.18723649e-01, 1.22883096e-01, 6.17144331e-02,\n         1.25747502e-01],\n        [3.79778519e-02, 1.08311079e-01, 7.02242672e-01, 6.74754605e-02,\n         8.39929730e-02],\n        [1.01204894e-01, 2.59623170e-01, 8.59790817e-02, 1.04520343e-01,\n         4.48672444e-01]], dtype=float32)}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(dataset, model.hyperparameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 6)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-d4e9730564a2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minference\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\Data_Science_all\\MSC_2_anno\\topic-modeling-evaluation-framework\\models\\TorchAvitm.py\u001B[0m in \u001B[0;36minference\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     75\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbool\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 77\u001B[1;33m         \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mavitm_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     78\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     79\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Data_Science_all\\MSC_2_anno\\topic-modeling-evaluation-framework\\models\\pytorchavitm\\avitm\\avitm.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, dataset, k)\u001B[0m\n\u001B[0;32m    280\u001B[0m                 \u001B[1;31m# forward pass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    281\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 282\u001B[1;33m                 \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mword_dists\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtopic_word\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtopic_document\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    283\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    284\u001B[0m                 \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mword_dists\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 6)"
     ]
    }
   ],
   "source": [
    "model.inference()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic diversity\n",
    "topic_diversity = Topic_diversity()\n",
    "\n",
    "# KL_Uniform\n",
    "#kl_uniform = KL_uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimization parameters\n",
    "opt_params = {}\n",
    "opt_params[\"n_calls\"] = 30\n",
    "opt_params[\"minimizer\"] = forest_minimize\n",
    "opt_params[\"different_iteration\"] = 3\n",
    "opt_params[\"n_random_starts\"] = 5\n",
    "#opt_params[\"extra_metrics\"] = [kl_uniform] # List of extra metrics\n",
    "opt_params[\"n_jobs\"] = mp.cpu_count() -1 # Enable multiprocessing\n",
    "opt_params[\"verbose\"] = True\n",
    "opt_params[\"save_path\"] = \"results\" #create folder if it doesn't exist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create search space for optimization\n",
    "search_space = {\n",
    "    \"num_epochs\": Integer(low=1, high=50),\n",
    "    #\"eta\": Real(low=0.01, high=5.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = Optimizer(\n",
    "    model,\n",
    "    dataset,\n",
    "    topic_diversity,\n",
    "    search_space,\n",
    "    opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable computing of topic document matrix to optimize performance\n",
    "optimizer.topic_document_matrix = False\n",
    "optimizer.topic_word_matrix = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "------------------------------------------\n",
      "Bayesian optimization parameters:\n",
      "-n_calls:  30 \n",
      "-different_iteration:  3 \n",
      "-n_random_starts:  5 \n",
      "-minimizer:  forest_minimize \n",
      "-acq_func:  LCB \n",
      "-kernel:  1**2 * Matern(length_scale=1, nu=1.5)\n",
      "------------------------------------------\n",
      "Iteration No: 1 started. Evaluating function at random point.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'n_components'",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-9745be50b19f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Optimize\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mres\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhyperparameters\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# Best values for the hyperparameters\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mres\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_values\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# Score of the optimized metric\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mC:\\Users\\terra\\PycharmProjects\\topic-modeling-evaluation-framework\\optimization\\optimizer.py\u001B[0m in \u001B[0;36moptimize\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1709\u001B[0m                             \u001B[0mxi\u001B[0m  \u001B[0;34m=\u001B[0m \u001B[0mdefault_parameters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"xi\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1710\u001B[0m                             \u001B[0mn_jobs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdefault_parameters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"n_jobs\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1711\u001B[0;31m                             \u001B[0mmodel_queue_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdefault_parameters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"model_queue_size\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1712\u001B[0m         )    \n\u001B[1;32m   1713\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mC:\\Users\\terra\\PycharmProjects\\topic-modeling-evaluation-framework\\optimization\\optimizer.py\u001B[0m in \u001B[0;36mBayesian_optimization\u001B[0;34m(self, f, bounds, minimizer, number_of_call, different_iteration, kernel, acq_func, base_estimator_forest, random_state, noise_level, alpha, kappa, X0, Y0, time_x0, n_random_starts, save, save_step, save_name, save_path, early_stop, early_step, plot, plot_name, log_scale_plot, verbose, n_points, xi, n_jobs, model_queue_size)\u001B[0m\n\u001B[1;32m    729\u001B[0m                                                 \u001B[0mkappa\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkappa\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    730\u001B[0m                                                 \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 731\u001B[0;31m                                                 model_queue_size=model_queue_size ) )\n\u001B[0m\u001B[1;32m    732\u001B[0m                 \u001B[0;32mif\u001B[0m\u001B[0;34m(\u001B[0m \u001B[0mplot\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;32mTrue\u001B[0m \u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    733\u001B[0m                     \u001B[0mname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mplot_name\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\".png\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mC:\\Users\\terra\\PycharmProjects\\topic-modeling-evaluation-framework\\venv\\lib\\site-packages\\skopt\\optimizer\\forest.py\u001B[0m in \u001B[0;36mforest_minimize\u001B[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs, model_queue_size)\u001B[0m\n\u001B[1;32m    174\u001B[0m                          \u001B[0mxi\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mxi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkappa\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkappa\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    175\u001B[0m                          \u001B[0mcallback\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcallback\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0macq_optimizer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"sampling\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 176\u001B[0;31m                          model_queue_size=model_queue_size)\n\u001B[0m",
      "\u001B[0;32mC:\\Users\\terra\\PycharmProjects\\topic-modeling-evaluation-framework\\venv\\lib\\site-packages\\skopt\\optimizer\\base.py\u001B[0m in \u001B[0;36mbase_minimize\u001B[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001B[0m\n\u001B[1;32m    270\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mn\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_calls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    271\u001B[0m         \u001B[0mnext_x\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 272\u001B[0;31m         \u001B[0mnext_y\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnext_x\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    273\u001B[0m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtell\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnext_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnext_y\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    274\u001B[0m         \u001B[0mresult\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspecs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspecs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mC:\\Users\\terra\\PycharmProjects\\topic-modeling-evaluation-framework\\optimization\\optimizer.py\u001B[0m in \u001B[0;36m_objective_function\u001B[0;34m(self, hyperparameters, path)\u001B[0m\n\u001B[1;32m    164\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtopk\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    165\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtopic_word_matrix\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 166\u001B[0;31m             self.topic_document_matrix)\n\u001B[0m\u001B[1;32m    167\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    168\u001B[0m         \u001B[0;31m#Save the models\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mC:\\Users\\terra\\PycharmProjects\\topic-modeling-evaluation-framework\\models\\TorchAvitm.py\u001B[0m in \u001B[0;36mtrain_model\u001B[0;34m(self, dataset, hyperparameters, top_words, topic_word_matrix, topic_document_matrix)\u001B[0m\n\u001B[1;32m     36\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtrain_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhyperparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtop_words\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopic_word_matrix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopic_document_matrix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_components\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhyperparameters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'n_components'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel_type\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhyperparameters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'model_type'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhidden_sizes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhyperparameters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'hidden_sizes'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'n_components'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Optimize\n",
    "res = optimizer.optimize()\n",
    "\n",
    "print(res.hyperparameters) # Best values for the hyperparameters\n",
    "print(res.function_values) # Score of the optimized metric\n",
    "print(\"Optimized metric: \"+res.optimized_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}