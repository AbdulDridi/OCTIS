{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.chdir(os.path.pardir)\n",
    "# Let them commented if you run this script in the main directory\n",
    "\n",
    "from models.LDA import LDA_Model\n",
    "from dataset.dataset import Dataset\n",
    "from optimization.optimizer import Optimizer\n",
    "from skopt.space.space import Real, Integer\n",
    "from skopt import gp_minimize, forest_minimize, dummy_minimize\n",
    "import multiprocessing as mp\n",
    "from optimization.optimizer import default_parameters as BO_parameters\n",
    "from evaluation_metrics.coherence_metrics import Coherence\n",
    "import time\n",
    "import resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_optimization(minimizer):\n",
    "    \"\"\"\n",
    "        Bayesian Optimization demo. \n",
    "        This function run one optimization with the \n",
    "        selected minimizer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        minimizer : gp_minimize, forest_minimize or dummy_minimize\n",
    "    \"\"\"\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = Dataset()\n",
    "    dataset.load(\"preprocessed_datasets/M10/M10_lemmatized_0\")\n",
    "        \n",
    "    # Load model\n",
    "    model = LDA_Model()\n",
    "\n",
    "    # Set model hyperparameters\n",
    "    model.hyperparameters.update({ \"num_topics\": 25, \"iterations\": 200 })\n",
    "    model.partitioning(False)\n",
    "\n",
    "    # Coherence word embeddings pairwise\n",
    "    parametri_metrica = {\n",
    "            'texts': dataset.get_corpus(),\n",
    "            'topk': 10,\n",
    "            'measure': 'c_npmi'\n",
    "    }\n",
    "    npmi = Coherence(parametri_metrica)\n",
    "\n",
    "    # Define optimization parameters for path (optional)\n",
    "    opt_params = {}\n",
    "    opt_params[\"minimizer\"] = minimizer\n",
    "\n",
    "    if opt_params[\"minimizer\"] == gp_minimize:\n",
    "            minimizer_stringa = \"gp_minimize\"\n",
    "    elif opt_params[\"minimizer\"] == dummy_minimize:\n",
    "        minimizer_stringa = \"random_minimize\"\n",
    "    elif opt_params[\"minimizer\"] == forest_minimize:\n",
    "        minimizer_stringa = \"forest_minimize\"\n",
    "    else:\n",
    "        minimizer_stringa = \"None\"\n",
    "\n",
    "    path_t = \"risultati/simple_\"+minimizer_stringa+\"/\"\n",
    "\n",
    "    # Define optimization parameters\n",
    "    opt_params[\"n_calls\"] = 5\n",
    "    opt_params[\"n_random_starts\"] = 2\n",
    "    opt_params[\"model_runs\"] = 3\n",
    "    opt_params[\"n_jobs\"] = mp.cpu_count() # Enable multiprocessing, if -1 do the same\n",
    "    opt_params[\"save\"] = False\n",
    "    opt_params[\"save_path\"] = path_t\n",
    "    opt_params[\"early_stop\"] = False\n",
    "    opt_params[\"plot_model\"]= True\n",
    "    opt_params[\"plot_best_seen\"] = True\n",
    "    opt_params[\"plot_prefix_name\"] = \"plot\"\n",
    "    opt_params[\"save_models\"] = True\n",
    "\n",
    "    # Create search space for optimization\n",
    "    search_space = {\n",
    "        \"alpha\": Real(low=0.001, high=5.0),\n",
    "        \"eta\": Real(low=0.001, high=5.0)\n",
    "    }\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = Optimizer(\n",
    "        model,\n",
    "        dataset,\n",
    "        npmi,\n",
    "        search_space,\n",
    "        opt_params)\n",
    "\n",
    "\n",
    "    # Optimize\n",
    "    start_time = time.time()\n",
    "    res = optimizer.optimize()\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time # Total time to optimize\n",
    "\n",
    "\n",
    "    print(res.hyperparameters) # Best values for the hyperparameters\n",
    "    print(res.function_values) # Score of the optimized metric\n",
    "    print(\"Optimized metric: \"+res.optimized_metric)\n",
    "    print(\"%s seconds\" % (total_time)) # Time to optimize\n",
    "\n",
    "    stringa_parameters = str(BO_parameters) + \"\\nTime: \" + str(total_time) + \" seconds\"\n",
    "\n",
    "    res.save(name =\"Result\", path = path_t, parameters = stringa_parameters)\n",
    "\n",
    "    print( resource.getrusage(resource.RUSAGE_SELF).ru_maxrss, \"Kbytes\" ) # RAM usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_demo_BO():\n",
    "    \"\"\"\n",
    "        Bayesian Optimization demo. \n",
    "        This function run 3 different optimization, one for base_minimize.\n",
    "    \"\"\"\n",
    "    minimize_list = [\n",
    "                    [dummy_minimize, \"random_minimize\"],\n",
    "                    [forest_minimize, \"forest_minimize\"],\n",
    "                    [gp_minimize, \"gp_minimize\"]\n",
    "                    ]\n",
    "\n",
    "    for minimize in minimize_list:\n",
    "        print(\"------------------------------------------\")\n",
    "        print(\"SIMPLE OPTIMIZATION with: \", minimize[1] )\n",
    "        simple_optimization(minimize[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_demo_BO()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
